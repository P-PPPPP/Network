{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy;\n",
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation and loss function;\n",
    "def func(f,x,y=None):\n",
    "    if f == 'relu':\n",
    "        return relu(x);\n",
    "    if f == 'softmax':\n",
    "        x = x.T - np.max(x,axis=1).T;\n",
    "        x = x.T\n",
    "        # softmax 自变量减去常量等同于分数上下同除相同常量\n",
    "        # 使得自变量尽量是负数，防止溢出\n",
    "        return softmax(x);\n",
    "    if f == 'sigmoid':\n",
    "        return sigmoid(x);\n",
    "    if f == 'x':\n",
    "        return x;\n",
    "    if f == 'MSE':\n",
    "        return 1/x.shape[0] * 1/2* np.sum((x - y)**2);\n",
    "    if f == 'Cross_Entropy':\n",
    "        res = - np.sum(y*np.log(x),axis=1);\n",
    "        return 1/x.shape[0] * np.sum(res);\n",
    "    if f == 'Real_Cross_Entropy':\n",
    "        res = - np.sum(y*np.log(x)+(1-y)*np.log(1-x),axis=1);\n",
    "        return 1/x.shape[0] * np.sum(res);\n",
    "def gra_func(f,x,y=None):\n",
    "    if f == 'relu':\n",
    "        return gra_relu(x);\n",
    "    if f =='softmax':\n",
    "        return gra_softmax(x);\n",
    "    if f == 'sigmoid':\n",
    "        return gra_sigmoid(x);\n",
    "    if f == 'x':\n",
    "        return 1;\n",
    "    if f == 'MSE':\n",
    "        return (x-y);\n",
    "    if f == 'Cross_Entropy':\n",
    "        return -y/x;\n",
    "    if f == 'Real_Cross_Entropy':\n",
    "        return -(y/x-(1-y)/(1-x));\n",
    "def relu(x):\n",
    "    res = np.abs(x);\n",
    "    res = (res + x)/2;\n",
    "    return res;\n",
    "def softmax(x):\n",
    "    x = x.T - np.max(x,axis=1).T;\n",
    "    x = x.T\n",
    "    out = np.exp(x).T/np.sum(np.exp(x),axis=1).T\n",
    "    out = out.T\n",
    "    return out;\n",
    "def sigmoid(x):\n",
    "    r1 = 1/(1+np.exp(-relu(x)));\n",
    "    r2 = np.exp(-relu(-x))/(1+np.exp(-relu(-x)));\n",
    "    return (r1+r2-1/2);\n",
    "def gra_relu(x):\n",
    "    res = np.abs(x);\n",
    "    res = np.sign(res + x);\n",
    "    return res;\n",
    "def gra_softmax(x):\n",
    "    x = x.T - np.max(x,axis=1).T;\n",
    "    x = x.T\n",
    "    out = np.exp(x).T/np.sum(np.exp(x),axis=1).T\n",
    "    out = out.T\n",
    "    return (out - out**2);\n",
    "def gra_sigmoid(x):\n",
    "    r1 = np.exp(-relu(x))/(1+np.exp(-relu(x)))**2;\n",
    "    r2 = np.exp(-relu(-x))/(1+np.exp(-relu(-x)))**2;\n",
    "    return (r1+r2-1/4);\n",
    "# 训练集随机化及从训练集产生测试集\n",
    "def random_division(x,y=None,test_rate = 0):\n",
    "    x = np.array(x);\n",
    "    # 数据总长度\n",
    "    n = np.shape(x)[0];\n",
    "    # 生成下表序列并随即打乱\n",
    "    sequence = np.array(range(n));\n",
    "    np.random.shuffle(sequence);\n",
    "    # 测试集长度\n",
    "    n_test = int(np.ceil(n * test_rate));\n",
    "    # 测试集序列与训练集序列\n",
    "    se_test = sequence[:n_test];\n",
    "    se_train = sequence[n_test:];\n",
    "    # 训练集\n",
    "    train_data = x[se_train];\n",
    "    # 测试集\n",
    "    test_data = x[se_test];\n",
    "    # 有监督学习的情况\n",
    "    if not type(y) == type(None):\n",
    "        y = np.array(y);\n",
    "        train_label = y[se_train];\n",
    "        test_label = y[se_test];\n",
    "        if not test_rate == 0:\n",
    "            return (train_data,train_label,test_data,test_label);\n",
    "        else:\n",
    "            return (train_data,train_label);\n",
    "    # 无监督情况\n",
    "    if not test_rate == 0:\n",
    "        return (train_data,test_data);\n",
    "    else:\n",
    "        return (train_data);\n",
    "# label to one-hot\n",
    "def onehot_label(label):\n",
    "    max_num = np.max(label);\n",
    "    res = [];\n",
    "    for k in range(len(label)):\n",
    "        resk = np.zeros((max_num+1,));\n",
    "        resk[label[k]] = 1;\n",
    "        res.append(resk);\n",
    "    return np.array(res);\n",
    "def arg_max(y):\n",
    "    tar = np.argmax(y,axis=1);\n",
    "    res = np.zeros_like(y);\n",
    "    for i in range(y.shape[0]):\n",
    "        res[i,tar[i]] = 1;\n",
    "    return res;\n",
    "def evaluate(y,label,metrics='Accuracy'):\n",
    "    confusion_matrix = np.dot(label.T,y);\n",
    "    cm = confusion_matrix;\n",
    "    # 对角线元素+1 防止溢出\n",
    "    cm = cm + np.eye(cm.shape[0]);\n",
    "    N = y.shape[0] + cm.shape[0];\n",
    "    n = y.shape[1];\n",
    "    T = np.diagonal(cm);\n",
    "    A = np.trace(cm)/N;\n",
    "    Pk = T/np.sum(cm,axis=0);\n",
    "    P = np.sum(Pk)/n;\n",
    "    Rk = T/np.sum(cm,axis=1).T;\n",
    "    R = np.sum(Rk)/n;\n",
    "    F1 = 2*P*R/(P+R);\n",
    "    if metrics == 'Accuracy':\n",
    "        return A;\n",
    "    if metrics == 'Precision':\n",
    "        return P;\n",
    "    if metrics == 'Recall':\n",
    "        return R;\n",
    "    if metrics == 'F1':\n",
    "        return F1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入数据\n",
    "names_to_label = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2};\n",
    "label_to_names = {value: key for key, value in names_to_label.items()}\n",
    "df = pd.read_csv('iris.data', header=None)\n",
    "xs = df.iloc[:, :4].values\n",
    "ts = np.array([names_to_label[name] for name in df.iloc[:, -1]])\n",
    "ys = np.zeros((ts.shape[0], 3));\n",
    "ts = ts.reshape(-1,1);\n",
    "# 标签one hot\n",
    "ts = onehot_label(ts);\n",
    "# 样本及标签顺序随机化\n",
    "(train_data,train_label) = random_division(xs,ts);\n",
    "# 对数据的归一化处理\n",
    "max_x = np.max(np.abs(train_data),axis=0);\n",
    "train_data = train_data / max_x;\n",
    "flag_loading = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构定义\n",
    "if not flag_loading == 1:\n",
    "    layers = 5;\n",
    "    nets = [16,64,256,32,3];\n",
    "    in_shape = [4] + nets[:-1];\n",
    "    out_shape = nets;\n",
    "    act_fun = ['relu','relu','relu','sigmoid','softmax'];\n",
    "    loss_func = 'Real_Cross_Entropy';\n",
    "    metrics = 'Accuracy';\n",
    "    x0 = train_data;\n",
    "    n = x0.shape[0];\n",
    "    m = x0.shape[1];\n",
    "    # 模型中间变量初始化\n",
    "    w = [];\n",
    "    b = [];\n",
    "    x = [];\n",
    "    y = [];\n",
    "    delta = [];\n",
    "    for i in range(layers):\n",
    "        wk = np.random.randn(in_shape[i],out_shape[i]);\n",
    "        bk = np.random.randn(1,nets[i]);\n",
    "        w.append(wk);\n",
    "        b.append(bk);\n",
    "        x.append([]);\n",
    "        y.append([]);\n",
    "        delta.append([]);\n",
    "# 保存初始化参数\n",
    "if flag_loading == 0:\n",
    "    flag_loading = 1;\n",
    "    w_init = copy.deepcopy(w);\n",
    "    b_init = copy.deepcopy(b);\n",
    "    x_init = copy.deepcopy(x);\n",
    "    y_init = copy.deepcopy(y);\n",
    "    delta_init = copy.deepcopy(delta);\n",
    "# 加载初始化参数\n",
    "w = copy.deepcopy(w_init);\n",
    "b = copy.deepcopy(b_init);\n",
    "x = copy.deepcopy(x_init);\n",
    "y = copy.deepcopy(y_init);\n",
    "delta = copy.deepcopy(delta_init);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: loss: 0.84 Accuracy:0.65 \n",
      "ep 1: loss: 0.84 Accuracy:0.65 \n",
      "ep 2: loss: 0.84 Accuracy:0.65 \n",
      "ep 3: loss: 0.84 Accuracy:0.65 \n",
      "ep 4: loss: 0.84 Accuracy:0.65 \n",
      "ep 5: loss: 0.84 Accuracy:0.65 \n",
      "ep 6: loss: 0.84 Accuracy:0.65 \n",
      "ep 7: loss: 0.83 Accuracy:0.65 \n",
      "ep 8: loss: 0.83 Accuracy:0.65 \n",
      "ep 9: loss: 0.83 Accuracy:0.65 \n",
      "ep 10: loss: 0.83 Accuracy:0.65 \n",
      "ep 11: loss: 0.83 Accuracy:0.65 \n",
      "ep 12: loss: 0.83 Accuracy:0.65 \n",
      "ep 13: loss: 0.83 Accuracy:0.65 \n",
      "ep 14: loss: 0.83 Accuracy:0.65 \n",
      "ep 15: loss: 0.83 Accuracy:0.65 \n",
      "ep 16: loss: 0.83 Accuracy:0.65 \n",
      "ep 17: loss: 0.83 Accuracy:0.65 \n",
      "ep 18: loss: 0.83 Accuracy:0.65 \n",
      "ep 19: loss: 0.83 Accuracy:0.65 \n",
      "ep 20: loss: 0.83 Accuracy:0.65 \n",
      "ep 21: loss: 0.82 Accuracy:0.65 \n",
      "ep 22: loss: 0.82 Accuracy:0.65 \n",
      "ep 23: loss: 0.82 Accuracy:0.65 \n",
      "ep 24: loss: 0.82 Accuracy:0.65 \n",
      "ep 25: loss: 0.82 Accuracy:0.65 \n",
      "ep 26: loss: 0.82 Accuracy:0.65 \n",
      "ep 27: loss: 0.82 Accuracy:0.65 \n",
      "ep 28: loss: 0.82 Accuracy:0.65 \n",
      "ep 29: loss: 0.82 Accuracy:0.65 \n",
      "ep 30: loss: 0.82 Accuracy:0.65 \n",
      "ep 31: loss: 0.82 Accuracy:0.65 \n",
      "ep 32: loss: 0.82 Accuracy:0.65 \n",
      "ep 33: loss: 0.82 Accuracy:0.65 \n",
      "ep 34: loss: 0.82 Accuracy:0.65 \n",
      "ep 35: loss: 0.82 Accuracy:0.65 \n",
      "ep 36: loss: 0.81 Accuracy:0.65 \n",
      "ep 37: loss: 0.81 Accuracy:0.65 \n",
      "ep 38: loss: 0.81 Accuracy:0.65 \n",
      "ep 39: loss: 0.81 Accuracy:0.65 \n",
      "ep 40: loss: 0.81 Accuracy:0.65 \n",
      "ep 41: loss: 0.81 Accuracy:0.65 \n",
      "ep 42: loss: 0.81 Accuracy:0.65 \n",
      "ep 43: loss: 0.81 Accuracy:0.65 \n",
      "ep 44: loss: 0.81 Accuracy:0.65 \n",
      "ep 45: loss: 0.81 Accuracy:0.65 \n",
      "ep 46: loss: 0.81 Accuracy:0.65 \n",
      "ep 47: loss: 0.81 Accuracy:0.65 \n",
      "ep 48: loss: 0.81 Accuracy:0.65 \n",
      "ep 49: loss: 0.81 Accuracy:0.65 \n",
      "ep 50: loss: 0.80 Accuracy:0.65 \n",
      "ep 51: loss: 0.80 Accuracy:0.65 \n",
      "ep 52: loss: 0.80 Accuracy:0.65 \n",
      "ep 53: loss: 0.80 Accuracy:0.65 \n",
      "ep 54: loss: 0.80 Accuracy:0.65 \n",
      "ep 55: loss: 0.80 Accuracy:0.65 \n",
      "ep 56: loss: 0.80 Accuracy:0.65 \n",
      "ep 57: loss: 0.80 Accuracy:0.65 \n",
      "ep 58: loss: 0.80 Accuracy:0.65 \n",
      "ep 59: loss: 0.80 Accuracy:0.65 \n",
      "ep 60: loss: 0.80 Accuracy:0.65 \n",
      "ep 61: loss: 0.80 Accuracy:0.65 \n",
      "ep 62: loss: 0.80 Accuracy:0.65 \n",
      "ep 63: loss: 0.80 Accuracy:0.65 \n",
      "ep 64: loss: 0.80 Accuracy:0.65 \n",
      "ep 65: loss: 0.79 Accuracy:0.65 \n",
      "ep 66: loss: 0.79 Accuracy:0.65 \n",
      "ep 67: loss: 0.79 Accuracy:0.65 \n",
      "ep 68: loss: 0.79 Accuracy:0.65 \n",
      "ep 69: loss: 0.79 Accuracy:0.65 \n",
      "ep 70: loss: 0.79 Accuracy:0.65 \n",
      "ep 71: loss: 0.79 Accuracy:0.65 \n",
      "ep 72: loss: 0.79 Accuracy:0.65 \n",
      "ep 73: loss: 0.79 Accuracy:0.65 \n",
      "ep 74: loss: 0.79 Accuracy:0.65 \n",
      "ep 75: loss: 0.79 Accuracy:0.65 \n",
      "ep 76: loss: 0.79 Accuracy:0.65 \n",
      "ep 77: loss: 0.79 Accuracy:0.65 \n",
      "ep 78: loss: 0.79 Accuracy:0.65 \n",
      "ep 79: loss: 0.79 Accuracy:0.65 \n",
      "ep 80: loss: 0.78 Accuracy:0.65 \n",
      "ep 81: loss: 0.78 Accuracy:0.65 \n",
      "ep 82: loss: 0.78 Accuracy:0.65 \n",
      "ep 83: loss: 0.78 Accuracy:0.65 \n",
      "ep 84: loss: 0.78 Accuracy:0.65 \n",
      "ep 85: loss: 0.78 Accuracy:0.65 \n",
      "ep 86: loss: 0.78 Accuracy:0.65 \n",
      "ep 87: loss: 0.78 Accuracy:0.65 \n",
      "ep 88: loss: 0.78 Accuracy:0.65 \n",
      "ep 89: loss: 0.78 Accuracy:0.65 \n",
      "ep 90: loss: 0.78 Accuracy:0.65 \n",
      "ep 91: loss: 0.78 Accuracy:0.65 \n",
      "ep 92: loss: 0.78 Accuracy:0.65 \n",
      "ep 93: loss: 0.78 Accuracy:0.65 \n",
      "ep 94: loss: 0.78 Accuracy:0.65 \n",
      "ep 95: loss: 0.77 Accuracy:0.65 \n",
      "ep 96: loss: 0.77 Accuracy:0.65 \n",
      "ep 97: loss: 0.77 Accuracy:0.65 \n",
      "ep 98: loss: 0.77 Accuracy:0.65 \n",
      "ep 99: loss: 0.77 Accuracy:0.65 \n",
      "ep 100: loss: 0.77 Accuracy:0.65 \n",
      "ep 101: loss: 0.77 Accuracy:0.65 \n",
      "ep 102: loss: 0.77 Accuracy:0.65 \n",
      "ep 103: loss: 0.77 Accuracy:0.65 \n",
      "ep 104: loss: 0.77 Accuracy:0.65 \n",
      "ep 105: loss: 0.77 Accuracy:0.65 \n",
      "ep 106: loss: 0.77 Accuracy:0.65 \n",
      "ep 107: loss: 0.77 Accuracy:0.65 \n",
      "ep 108: loss: 0.77 Accuracy:0.65 \n",
      "ep 109: loss: 0.77 Accuracy:0.65 \n",
      "ep 110: loss: 0.76 Accuracy:0.65 \n",
      "ep 111: loss: 0.76 Accuracy:0.65 \n",
      "ep 112: loss: 0.76 Accuracy:0.65 \n",
      "ep 113: loss: 0.76 Accuracy:0.65 \n",
      "ep 114: loss: 0.76 Accuracy:0.65 \n",
      "ep 115: loss: 0.76 Accuracy:0.65 \n",
      "ep 116: loss: 0.76 Accuracy:0.65 \n",
      "ep 117: loss: 0.76 Accuracy:0.65 \n",
      "ep 118: loss: 0.76 Accuracy:0.65 \n",
      "ep 119: loss: 0.76 Accuracy:0.65 \n",
      "ep 120: loss: 0.76 Accuracy:0.65 \n",
      "ep 121: loss: 0.76 Accuracy:0.65 \n",
      "ep 122: loss: 0.76 Accuracy:0.65 \n",
      "ep 123: loss: 0.76 Accuracy:0.65 \n",
      "ep 124: loss: 0.76 Accuracy:0.65 \n",
      "ep 125: loss: 0.76 Accuracy:0.65 \n",
      "ep 126: loss: 0.75 Accuracy:0.65 \n",
      "ep 127: loss: 0.75 Accuracy:0.65 \n",
      "ep 128: loss: 0.75 Accuracy:0.65 \n",
      "ep 129: loss: 0.75 Accuracy:0.65 \n",
      "ep 130: loss: 0.75 Accuracy:0.65 \n",
      "ep 131: loss: 0.75 Accuracy:0.65 \n",
      "ep 132: loss: 0.75 Accuracy:0.65 \n",
      "ep 133: loss: 0.75 Accuracy:0.65 \n",
      "ep 134: loss: 0.75 Accuracy:0.65 \n",
      "ep 135: loss: 0.75 Accuracy:0.65 \n",
      "ep 136: loss: 0.75 Accuracy:0.65 \n",
      "ep 137: loss: 0.75 Accuracy:0.65 \n",
      "ep 138: loss: 0.75 Accuracy:0.65 \n",
      "ep 139: loss: 0.75 Accuracy:0.65 \n",
      "ep 140: loss: 0.75 Accuracy:0.65 \n",
      "ep 141: loss: 0.75 Accuracy:0.65 \n",
      "ep 142: loss: 0.74 Accuracy:0.65 \n",
      "ep 143: loss: 0.74 Accuracy:0.65 \n",
      "ep 144: loss: 0.74 Accuracy:0.65 \n",
      "ep 145: loss: 0.74 Accuracy:0.65 \n",
      "ep 146: loss: 0.74 Accuracy:0.65 \n",
      "ep 147: loss: 0.74 Accuracy:0.65 \n",
      "ep 148: loss: 0.74 Accuracy:0.65 \n",
      "ep 149: loss: 0.74 Accuracy:0.65 \n",
      "ep 150: loss: 0.74 Accuracy:0.65 \n",
      "ep 151: loss: 0.74 Accuracy:0.65 \n",
      "ep 152: loss: 0.74 Accuracy:0.65 \n",
      "ep 153: loss: 0.74 Accuracy:0.65 \n",
      "ep 154: loss: 0.74 Accuracy:0.65 \n",
      "ep 155: loss: 0.74 Accuracy:0.65 \n",
      "ep 156: loss: 0.74 Accuracy:0.65 \n",
      "ep 157: loss: 0.74 Accuracy:0.65 \n",
      "ep 158: loss: 0.73 Accuracy:0.65 \n",
      "ep 159: loss: 0.73 Accuracy:0.65 \n",
      "ep 160: loss: 0.73 Accuracy:0.65 \n",
      "ep 161: loss: 0.73 Accuracy:0.65 \n",
      "ep 162: loss: 0.73 Accuracy:0.65 \n",
      "ep 163: loss: 0.73 Accuracy:0.65 \n",
      "ep 164: loss: 0.73 Accuracy:0.65 \n",
      "ep 165: loss: 0.73 Accuracy:0.65 \n",
      "ep 166: loss: 0.73 Accuracy:0.65 \n",
      "ep 167: loss: 0.73 Accuracy:0.65 \n",
      "ep 168: loss: 0.73 Accuracy:0.65 \n",
      "ep 169: loss: 0.73 Accuracy:0.65 \n",
      "ep 170: loss: 0.73 Accuracy:0.65 \n",
      "ep 171: loss: 0.73 Accuracy:0.65 \n",
      "ep 172: loss: 0.73 Accuracy:0.65 \n",
      "ep 173: loss: 0.73 Accuracy:0.65 \n",
      "ep 174: loss: 0.72 Accuracy:0.65 \n",
      "ep 175: loss: 0.72 Accuracy:0.65 \n",
      "ep 176: loss: 0.72 Accuracy:0.65 \n",
      "ep 177: loss: 0.72 Accuracy:0.65 \n",
      "ep 178: loss: 0.72 Accuracy:0.65 \n",
      "ep 179: loss: 0.72 Accuracy:0.65 \n",
      "ep 180: loss: 0.72 Accuracy:0.65 \n",
      "ep 181: loss: 0.72 Accuracy:0.65 \n",
      "ep 182: loss: 0.72 Accuracy:0.65 \n",
      "ep 183: loss: 0.72 Accuracy:0.65 \n",
      "ep 184: loss: 0.72 Accuracy:0.65 \n",
      "ep 185: loss: 0.72 Accuracy:0.65 \n",
      "ep 186: loss: 0.72 Accuracy:0.65 \n",
      "ep 187: loss: 0.72 Accuracy:0.65 \n",
      "ep 188: loss: 0.72 Accuracy:0.65 \n",
      "ep 189: loss: 0.72 Accuracy:0.65 \n",
      "ep 190: loss: 0.72 Accuracy:0.65 \n",
      "ep 191: loss: 0.71 Accuracy:0.65 \n",
      "ep 192: loss: 0.71 Accuracy:0.65 \n",
      "ep 193: loss: 0.71 Accuracy:0.65 \n",
      "ep 194: loss: 0.71 Accuracy:0.65 \n",
      "ep 195: loss: 0.71 Accuracy:0.65 \n",
      "ep 196: loss: 0.71 Accuracy:0.65 \n",
      "ep 197: loss: 0.71 Accuracy:0.65 \n",
      "ep 198: loss: 0.71 Accuracy:0.65 \n",
      "ep 199: loss: 0.71 Accuracy:0.65 \n",
      "ep 200: loss: 0.71 Accuracy:0.65 \n",
      "ep 201: loss: 0.71 Accuracy:0.65 \n",
      "ep 202: loss: 0.71 Accuracy:0.65 \n",
      "ep 203: loss: 0.71 Accuracy:0.65 \n",
      "ep 204: loss: 0.71 Accuracy:0.65 \n",
      "ep 205: loss: 0.71 Accuracy:0.65 \n",
      "ep 206: loss: 0.71 Accuracy:0.65 \n",
      "ep 207: loss: 0.71 Accuracy:0.65 \n",
      "ep 208: loss: 0.70 Accuracy:0.65 \n",
      "ep 209: loss: 0.70 Accuracy:0.65 \n",
      "ep 210: loss: 0.70 Accuracy:0.65 \n",
      "ep 211: loss: 0.70 Accuracy:0.65 \n",
      "ep 212: loss: 0.70 Accuracy:0.65 \n",
      "ep 213: loss: 0.70 Accuracy:0.65 \n",
      "ep 214: loss: 0.70 Accuracy:0.65 \n",
      "ep 215: loss: 0.70 Accuracy:0.65 \n",
      "ep 216: loss: 0.70 Accuracy:0.65 \n",
      "ep 217: loss: 0.70 Accuracy:0.65 \n",
      "ep 218: loss: 0.70 Accuracy:0.65 \n",
      "ep 219: loss: 0.70 Accuracy:0.65 \n",
      "ep 220: loss: 0.70 Accuracy:0.65 \n",
      "ep 221: loss: 0.70 Accuracy:0.65 \n",
      "ep 222: loss: 0.70 Accuracy:0.65 \n",
      "ep 223: loss: 0.70 Accuracy:0.65 \n",
      "ep 224: loss: 0.70 Accuracy:0.65 \n",
      "ep 225: loss: 0.69 Accuracy:0.65 \n",
      "ep 226: loss: 0.69 Accuracy:0.65 \n",
      "ep 227: loss: 0.69 Accuracy:0.65 \n",
      "ep 228: loss: 0.69 Accuracy:0.65 \n",
      "ep 229: loss: 0.69 Accuracy:0.65 \n",
      "ep 230: loss: 0.69 Accuracy:0.65 \n",
      "ep 231: loss: 0.69 Accuracy:0.65 \n",
      "ep 232: loss: 0.69 Accuracy:0.65 \n",
      "ep 233: loss: 0.69 Accuracy:0.65 \n",
      "ep 234: loss: 0.69 Accuracy:0.65 \n",
      "ep 235: loss: 0.69 Accuracy:0.65 \n",
      "ep 236: loss: 0.69 Accuracy:0.65 \n",
      "ep 237: loss: 0.69 Accuracy:0.65 \n",
      "ep 238: loss: 0.69 Accuracy:0.65 \n",
      "ep 239: loss: 0.69 Accuracy:0.65 \n",
      "ep 240: loss: 0.69 Accuracy:0.65 \n",
      "ep 241: loss: 0.69 Accuracy:0.65 \n",
      "ep 242: loss: 0.69 Accuracy:0.65 \n",
      "ep 243: loss: 0.68 Accuracy:0.65 \n",
      "ep 244: loss: 0.68 Accuracy:0.65 \n",
      "ep 245: loss: 0.68 Accuracy:0.65 \n",
      "ep 246: loss: 0.68 Accuracy:0.65 \n",
      "ep 247: loss: 0.68 Accuracy:0.65 \n",
      "ep 248: loss: 0.68 Accuracy:0.65 \n",
      "ep 249: loss: 0.68 Accuracy:0.65 \n",
      "ep 250: loss: 0.68 Accuracy:0.65 \n",
      "ep 251: loss: 0.68 Accuracy:0.65 \n",
      "ep 252: loss: 0.68 Accuracy:0.65 \n",
      "ep 253: loss: 0.68 Accuracy:0.65 \n",
      "ep 254: loss: 0.68 Accuracy:0.65 \n",
      "ep 255: loss: 0.68 Accuracy:0.65 \n",
      "ep 256: loss: 0.68 Accuracy:0.65 \n",
      "ep 257: loss: 0.68 Accuracy:0.65 \n",
      "ep 258: loss: 0.68 Accuracy:0.65 \n",
      "ep 259: loss: 0.68 Accuracy:0.65 \n",
      "ep 260: loss: 0.68 Accuracy:0.65 \n",
      "ep 261: loss: 0.67 Accuracy:0.65 \n",
      "ep 262: loss: 0.67 Accuracy:0.65 \n",
      "ep 263: loss: 0.67 Accuracy:0.65 \n",
      "ep 264: loss: 0.67 Accuracy:0.65 \n",
      "ep 265: loss: 0.67 Accuracy:0.65 \n",
      "ep 266: loss: 0.67 Accuracy:0.65 \n",
      "ep 267: loss: 0.67 Accuracy:0.65 \n",
      "ep 268: loss: 0.67 Accuracy:0.65 \n",
      "ep 269: loss: 0.67 Accuracy:0.65 \n",
      "ep 270: loss: 0.67 Accuracy:0.65 \n",
      "ep 271: loss: 0.67 Accuracy:0.65 \n",
      "ep 272: loss: 0.67 Accuracy:0.65 \n",
      "ep 273: loss: 0.67 Accuracy:0.65 \n",
      "ep 274: loss: 0.67 Accuracy:0.65 \n",
      "ep 275: loss: 0.67 Accuracy:0.65 \n",
      "ep 276: loss: 0.67 Accuracy:0.65 \n",
      "ep 277: loss: 0.67 Accuracy:0.65 \n",
      "ep 278: loss: 0.67 Accuracy:0.65 \n",
      "ep 279: loss: 0.66 Accuracy:0.65 \n",
      "ep 280: loss: 0.66 Accuracy:0.65 \n",
      "ep 281: loss: 0.66 Accuracy:0.65 \n",
      "ep 282: loss: 0.66 Accuracy:0.65 \n",
      "ep 283: loss: 0.66 Accuracy:0.65 \n",
      "ep 284: loss: 0.66 Accuracy:0.65 \n",
      "ep 285: loss: 0.66 Accuracy:0.65 \n",
      "ep 286: loss: 0.66 Accuracy:0.65 \n",
      "ep 287: loss: 0.66 Accuracy:0.65 \n",
      "ep 288: loss: 0.66 Accuracy:0.65 \n",
      "ep 289: loss: 0.66 Accuracy:0.65 \n",
      "ep 290: loss: 0.66 Accuracy:0.65 \n",
      "ep 291: loss: 0.66 Accuracy:0.65 \n",
      "ep 292: loss: 0.66 Accuracy:0.65 \n",
      "ep 293: loss: 0.66 Accuracy:0.65 \n",
      "ep 294: loss: 0.66 Accuracy:0.65 \n",
      "ep 295: loss: 0.66 Accuracy:0.65 \n",
      "ep 296: loss: 0.66 Accuracy:0.65 \n",
      "ep 297: loss: 0.66 Accuracy:0.65 \n",
      "ep 298: loss: 0.65 Accuracy:0.65 \n",
      "ep 299: loss: 0.65 Accuracy:0.65 \n",
      "ep 300: loss: 0.65 Accuracy:0.65 \n",
      "ep 301: loss: 0.65 Accuracy:0.65 \n",
      "ep 302: loss: 0.65 Accuracy:0.65 \n",
      "ep 303: loss: 0.65 Accuracy:0.65 \n",
      "ep 304: loss: 0.65 Accuracy:0.65 \n",
      "ep 305: loss: 0.65 Accuracy:0.65 \n",
      "ep 306: loss: 0.65 Accuracy:0.65 \n",
      "ep 307: loss: 0.65 Accuracy:0.65 \n",
      "ep 308: loss: 0.65 Accuracy:0.65 \n",
      "ep 309: loss: 0.65 Accuracy:0.65 \n",
      "ep 310: loss: 0.65 Accuracy:0.65 \n",
      "ep 311: loss: 0.65 Accuracy:0.65 \n",
      "ep 312: loss: 0.65 Accuracy:0.65 \n",
      "ep 313: loss: 0.65 Accuracy:0.65 \n",
      "ep 314: loss: 0.65 Accuracy:0.65 \n",
      "ep 315: loss: 0.65 Accuracy:0.65 \n",
      "ep 316: loss: 0.65 Accuracy:0.65 \n",
      "ep 317: loss: 0.64 Accuracy:0.65 \n",
      "ep 318: loss: 0.64 Accuracy:0.65 \n",
      "ep 319: loss: 0.64 Accuracy:0.65 \n",
      "ep 320: loss: 0.64 Accuracy:0.65 \n",
      "ep 321: loss: 0.64 Accuracy:0.65 \n",
      "ep 322: loss: 0.64 Accuracy:0.65 \n",
      "ep 323: loss: 0.64 Accuracy:0.65 \n",
      "ep 324: loss: 0.64 Accuracy:0.65 \n",
      "ep 325: loss: 0.64 Accuracy:0.65 \n",
      "ep 326: loss: 0.64 Accuracy:0.65 \n",
      "ep 327: loss: 0.64 Accuracy:0.65 \n",
      "ep 328: loss: 0.64 Accuracy:0.65 \n",
      "ep 329: loss: 0.64 Accuracy:0.65 \n",
      "ep 330: loss: 0.64 Accuracy:0.65 \n",
      "ep 331: loss: 0.64 Accuracy:0.65 \n",
      "ep 332: loss: 0.64 Accuracy:0.65 \n",
      "ep 333: loss: 0.64 Accuracy:0.65 \n",
      "ep 334: loss: 0.64 Accuracy:0.65 \n",
      "ep 335: loss: 0.64 Accuracy:0.65 \n",
      "ep 336: loss: 0.64 Accuracy:0.65 \n",
      "ep 337: loss: 0.63 Accuracy:0.65 \n",
      "ep 338: loss: 0.63 Accuracy:0.65 \n",
      "ep 339: loss: 0.63 Accuracy:0.65 \n",
      "ep 340: loss: 0.63 Accuracy:0.65 \n",
      "ep 341: loss: 0.63 Accuracy:0.65 \n",
      "ep 342: loss: 0.63 Accuracy:0.65 \n",
      "ep 343: loss: 0.63 Accuracy:0.65 \n",
      "ep 344: loss: 0.63 Accuracy:0.65 \n",
      "ep 345: loss: 0.63 Accuracy:0.65 \n",
      "ep 346: loss: 0.63 Accuracy:0.65 \n",
      "ep 347: loss: 0.63 Accuracy:0.65 \n",
      "ep 348: loss: 0.63 Accuracy:0.65 \n",
      "ep 349: loss: 0.63 Accuracy:0.65 \n",
      "ep 350: loss: 0.63 Accuracy:0.65 \n",
      "ep 351: loss: 0.63 Accuracy:0.65 \n",
      "ep 352: loss: 0.63 Accuracy:0.65 \n",
      "ep 353: loss: 0.63 Accuracy:0.65 \n",
      "ep 354: loss: 0.63 Accuracy:0.65 \n",
      "ep 355: loss: 0.63 Accuracy:0.65 \n",
      "ep 356: loss: 0.63 Accuracy:0.65 \n",
      "ep 357: loss: 0.62 Accuracy:0.65 \n",
      "ep 358: loss: 0.62 Accuracy:0.65 \n",
      "ep 359: loss: 0.62 Accuracy:0.65 \n",
      "ep 360: loss: 0.62 Accuracy:0.65 \n",
      "ep 361: loss: 0.62 Accuracy:0.65 \n",
      "ep 362: loss: 0.62 Accuracy:0.65 \n",
      "ep 363: loss: 0.62 Accuracy:0.65 \n",
      "ep 364: loss: 0.62 Accuracy:0.65 \n",
      "ep 365: loss: 0.62 Accuracy:0.65 \n",
      "ep 366: loss: 0.62 Accuracy:0.65 \n",
      "ep 367: loss: 0.62 Accuracy:0.65 \n",
      "ep 368: loss: 0.62 Accuracy:0.65 \n",
      "ep 369: loss: 0.62 Accuracy:0.65 \n",
      "ep 370: loss: 0.62 Accuracy:0.65 \n",
      "ep 371: loss: 0.62 Accuracy:0.65 \n",
      "ep 372: loss: 0.62 Accuracy:0.65 \n",
      "ep 373: loss: 0.62 Accuracy:0.65 \n",
      "ep 374: loss: 0.62 Accuracy:0.65 \n",
      "ep 375: loss: 0.62 Accuracy:0.65 \n",
      "ep 376: loss: 0.62 Accuracy:0.65 \n",
      "ep 377: loss: 0.62 Accuracy:0.65 \n",
      "ep 378: loss: 0.61 Accuracy:0.65 \n",
      "ep 379: loss: 0.61 Accuracy:0.65 \n",
      "ep 380: loss: 0.61 Accuracy:0.65 \n",
      "ep 381: loss: 0.61 Accuracy:0.65 \n",
      "ep 382: loss: 0.61 Accuracy:0.65 \n",
      "ep 383: loss: 0.61 Accuracy:0.65 \n",
      "ep 384: loss: 0.61 Accuracy:0.65 \n",
      "ep 385: loss: 0.61 Accuracy:0.65 \n",
      "ep 386: loss: 0.61 Accuracy:0.65 \n",
      "ep 387: loss: 0.61 Accuracy:0.65 \n",
      "ep 388: loss: 0.61 Accuracy:0.65 \n",
      "ep 389: loss: 0.61 Accuracy:0.65 \n",
      "ep 390: loss: 0.61 Accuracy:0.65 \n",
      "ep 391: loss: 0.61 Accuracy:0.65 \n",
      "ep 392: loss: 0.61 Accuracy:0.65 \n",
      "ep 393: loss: 0.61 Accuracy:0.65 \n",
      "ep 394: loss: 0.61 Accuracy:0.65 \n",
      "ep 395: loss: 0.61 Accuracy:0.65 \n",
      "ep 396: loss: 0.61 Accuracy:0.65 \n",
      "ep 397: loss: 0.61 Accuracy:0.65 \n",
      "ep 398: loss: 0.61 Accuracy:0.65 \n",
      "ep 399: loss: 0.60 Accuracy:0.65 \n",
      "ep 400: loss: 0.60 Accuracy:0.65 \n",
      "ep 401: loss: 0.60 Accuracy:0.65 \n",
      "ep 402: loss: 0.60 Accuracy:0.65 \n",
      "ep 403: loss: 0.60 Accuracy:0.65 \n",
      "ep 404: loss: 0.60 Accuracy:0.65 \n",
      "ep 405: loss: 0.60 Accuracy:0.65 \n",
      "ep 406: loss: 0.60 Accuracy:0.65 \n",
      "ep 407: loss: 0.60 Accuracy:0.65 \n",
      "ep 408: loss: 0.60 Accuracy:0.65 \n",
      "ep 409: loss: 0.60 Accuracy:0.65 \n",
      "ep 410: loss: 0.60 Accuracy:0.65 \n",
      "ep 411: loss: 0.60 Accuracy:0.65 \n",
      "ep 412: loss: 0.60 Accuracy:0.65 \n",
      "ep 413: loss: 0.60 Accuracy:0.65 \n",
      "ep 414: loss: 0.60 Accuracy:0.65 \n",
      "ep 415: loss: 0.60 Accuracy:0.65 \n",
      "ep 416: loss: 0.60 Accuracy:0.65 \n",
      "ep 417: loss: 0.60 Accuracy:0.65 \n",
      "ep 418: loss: 0.60 Accuracy:0.65 \n",
      "ep 419: loss: 0.60 Accuracy:0.65 \n",
      "ep 420: loss: 0.60 Accuracy:0.65 \n",
      "ep 421: loss: 0.59 Accuracy:0.65 \n",
      "ep 422: loss: 0.59 Accuracy:0.65 \n",
      "ep 423: loss: 0.59 Accuracy:0.65 \n",
      "ep 424: loss: 0.59 Accuracy:0.65 \n",
      "ep 425: loss: 0.59 Accuracy:0.65 \n",
      "ep 426: loss: 0.59 Accuracy:0.65 \n",
      "ep 427: loss: 0.59 Accuracy:0.65 \n",
      "ep 428: loss: 0.59 Accuracy:0.65 \n",
      "ep 429: loss: 0.59 Accuracy:0.65 \n",
      "ep 430: loss: 0.59 Accuracy:0.65 \n",
      "ep 431: loss: 0.59 Accuracy:0.65 \n",
      "ep 432: loss: 0.59 Accuracy:0.65 \n",
      "ep 433: loss: 0.59 Accuracy:0.65 \n",
      "ep 434: loss: 0.59 Accuracy:0.65 \n",
      "ep 435: loss: 0.59 Accuracy:0.65 \n",
      "ep 436: loss: 0.59 Accuracy:0.65 \n",
      "ep 437: loss: 0.59 Accuracy:0.65 \n",
      "ep 438: loss: 0.59 Accuracy:0.65 \n",
      "ep 439: loss: 0.59 Accuracy:0.65 \n",
      "ep 440: loss: 0.59 Accuracy:0.65 \n",
      "ep 441: loss: 0.59 Accuracy:0.65 \n",
      "ep 442: loss: 0.59 Accuracy:0.65 \n",
      "ep 443: loss: 0.59 Accuracy:0.65 \n",
      "ep 444: loss: 0.58 Accuracy:0.65 \n",
      "ep 445: loss: 0.58 Accuracy:0.65 \n",
      "ep 446: loss: 0.58 Accuracy:0.65 \n",
      "ep 447: loss: 0.58 Accuracy:0.65 \n",
      "ep 448: loss: 0.58 Accuracy:0.65 \n",
      "ep 449: loss: 0.58 Accuracy:0.65 \n",
      "ep 450: loss: 0.58 Accuracy:0.65 \n",
      "ep 451: loss: 0.58 Accuracy:0.65 \n",
      "ep 452: loss: 0.58 Accuracy:0.65 \n",
      "ep 453: loss: 0.58 Accuracy:0.65 \n",
      "ep 454: loss: 0.58 Accuracy:0.65 \n",
      "ep 455: loss: 0.58 Accuracy:0.65 \n",
      "ep 456: loss: 0.58 Accuracy:0.65 \n",
      "ep 457: loss: 0.58 Accuracy:0.65 \n",
      "ep 458: loss: 0.58 Accuracy:0.65 \n",
      "ep 459: loss: 0.58 Accuracy:0.65 \n",
      "ep 460: loss: 0.58 Accuracy:0.65 \n",
      "ep 461: loss: 0.58 Accuracy:0.65 \n",
      "ep 462: loss: 0.58 Accuracy:0.65 \n",
      "ep 463: loss: 0.58 Accuracy:0.65 \n",
      "ep 464: loss: 0.58 Accuracy:0.65 \n",
      "ep 465: loss: 0.58 Accuracy:0.65 \n",
      "ep 466: loss: 0.58 Accuracy:0.65 \n",
      "ep 467: loss: 0.58 Accuracy:0.65 \n",
      "ep 468: loss: 0.57 Accuracy:0.65 \n",
      "ep 469: loss: 0.57 Accuracy:0.65 \n",
      "ep 470: loss: 0.57 Accuracy:0.65 \n",
      "ep 471: loss: 0.57 Accuracy:0.65 \n",
      "ep 472: loss: 0.57 Accuracy:0.65 \n",
      "ep 473: loss: 0.57 Accuracy:0.65 \n",
      "ep 474: loss: 0.57 Accuracy:0.65 \n",
      "ep 475: loss: 0.57 Accuracy:0.65 \n",
      "ep 476: loss: 0.57 Accuracy:0.65 \n",
      "ep 477: loss: 0.57 Accuracy:0.65 \n",
      "ep 478: loss: 0.57 Accuracy:0.65 \n",
      "ep 479: loss: 0.57 Accuracy:0.65 \n",
      "ep 480: loss: 0.57 Accuracy:0.65 \n",
      "ep 481: loss: 0.57 Accuracy:0.65 \n",
      "ep 482: loss: 0.57 Accuracy:0.65 \n",
      "ep 483: loss: 0.57 Accuracy:0.65 \n",
      "ep 484: loss: 0.57 Accuracy:0.65 \n",
      "ep 485: loss: 0.57 Accuracy:0.65 \n",
      "ep 486: loss: 0.57 Accuracy:0.65 \n",
      "ep 487: loss: 0.57 Accuracy:0.65 \n",
      "ep 488: loss: 0.57 Accuracy:0.65 \n",
      "ep 489: loss: 0.57 Accuracy:0.65 \n",
      "ep 490: loss: 0.57 Accuracy:0.65 \n",
      "ep 491: loss: 0.57 Accuracy:0.65 \n",
      "ep 492: loss: 0.56 Accuracy:0.65 \n",
      "ep 493: loss: 0.56 Accuracy:0.65 \n",
      "ep 494: loss: 0.56 Accuracy:0.65 \n",
      "ep 495: loss: 0.56 Accuracy:0.65 \n",
      "ep 496: loss: 0.56 Accuracy:0.65 \n",
      "ep 497: loss: 0.56 Accuracy:0.65 \n",
      "ep 498: loss: 0.56 Accuracy:0.65 \n",
      "ep 499: loss: 0.56 Accuracy:0.65 \n",
      "ep 500: loss: 0.56 Accuracy:0.65 \n",
      "ep 501: loss: 0.56 Accuracy:0.65 \n",
      "ep 502: loss: 0.56 Accuracy:0.65 \n",
      "ep 503: loss: 0.56 Accuracy:0.65 \n",
      "ep 504: loss: 0.56 Accuracy:0.65 \n",
      "ep 505: loss: 0.56 Accuracy:0.65 \n",
      "ep 506: loss: 0.56 Accuracy:0.65 \n",
      "ep 507: loss: 0.56 Accuracy:0.65 \n",
      "ep 508: loss: 0.56 Accuracy:0.65 \n",
      "ep 509: loss: 0.56 Accuracy:0.65 \n",
      "ep 510: loss: 0.56 Accuracy:0.65 \n",
      "ep 511: loss: 0.56 Accuracy:0.65 \n",
      "ep 512: loss: 0.56 Accuracy:0.65 \n",
      "ep 513: loss: 0.56 Accuracy:0.65 \n",
      "ep 514: loss: 0.56 Accuracy:0.65 \n",
      "ep 515: loss: 0.56 Accuracy:0.65 \n",
      "ep 516: loss: 0.56 Accuracy:0.65 \n",
      "ep 517: loss: 0.55 Accuracy:0.65 \n",
      "ep 518: loss: 0.55 Accuracy:0.65 \n",
      "ep 519: loss: 0.55 Accuracy:0.65 \n",
      "ep 520: loss: 0.55 Accuracy:0.65 \n",
      "ep 521: loss: 0.55 Accuracy:0.65 \n",
      "ep 522: loss: 0.55 Accuracy:0.65 \n",
      "ep 523: loss: 0.55 Accuracy:0.65 \n",
      "ep 524: loss: 0.55 Accuracy:0.65 \n",
      "ep 525: loss: 0.55 Accuracy:0.65 \n",
      "ep 526: loss: 0.55 Accuracy:0.65 \n",
      "ep 527: loss: 0.55 Accuracy:0.65 \n",
      "ep 528: loss: 0.55 Accuracy:0.65 \n",
      "ep 529: loss: 0.55 Accuracy:0.65 \n",
      "ep 530: loss: 0.55 Accuracy:0.65 \n",
      "ep 531: loss: 0.55 Accuracy:0.65 \n",
      "ep 532: loss: 0.55 Accuracy:0.65 \n",
      "ep 533: loss: 0.55 Accuracy:0.65 \n",
      "ep 534: loss: 0.55 Accuracy:0.65 \n",
      "ep 535: loss: 0.55 Accuracy:0.65 \n",
      "ep 536: loss: 0.55 Accuracy:0.65 \n",
      "ep 537: loss: 0.55 Accuracy:0.65 \n",
      "ep 538: loss: 0.55 Accuracy:0.65 \n",
      "ep 539: loss: 0.55 Accuracy:0.65 \n",
      "ep 540: loss: 0.55 Accuracy:0.65 \n",
      "ep 541: loss: 0.55 Accuracy:0.65 \n",
      "ep 542: loss: 0.55 Accuracy:0.65 \n",
      "ep 543: loss: 0.55 Accuracy:0.65 \n",
      "ep 544: loss: 0.54 Accuracy:0.65 \n",
      "ep 545: loss: 0.54 Accuracy:0.65 \n",
      "ep 546: loss: 0.54 Accuracy:0.65 \n",
      "ep 547: loss: 0.54 Accuracy:0.65 \n",
      "ep 548: loss: 0.54 Accuracy:0.65 \n",
      "ep 549: loss: 0.54 Accuracy:0.65 \n",
      "ep 550: loss: 0.54 Accuracy:0.65 \n",
      "ep 551: loss: 0.54 Accuracy:0.65 \n",
      "ep 552: loss: 0.54 Accuracy:0.65 \n",
      "ep 553: loss: 0.54 Accuracy:0.65 \n",
      "ep 554: loss: 0.54 Accuracy:0.65 \n",
      "ep 555: loss: 0.54 Accuracy:0.65 \n",
      "ep 556: loss: 0.54 Accuracy:0.65 \n",
      "ep 557: loss: 0.54 Accuracy:0.65 \n",
      "ep 558: loss: 0.54 Accuracy:0.65 \n",
      "ep 559: loss: 0.54 Accuracy:0.65 \n",
      "ep 560: loss: 0.54 Accuracy:0.65 \n",
      "ep 561: loss: 0.54 Accuracy:0.65 \n",
      "ep 562: loss: 0.54 Accuracy:0.65 \n",
      "ep 563: loss: 0.54 Accuracy:0.65 \n",
      "ep 564: loss: 0.54 Accuracy:0.65 \n",
      "ep 565: loss: 0.54 Accuracy:0.65 \n",
      "ep 566: loss: 0.54 Accuracy:0.65 \n",
      "ep 567: loss: 0.54 Accuracy:0.65 \n",
      "ep 568: loss: 0.54 Accuracy:0.65 \n",
      "ep 569: loss: 0.54 Accuracy:0.65 \n",
      "ep 570: loss: 0.54 Accuracy:0.65 \n",
      "ep 571: loss: 0.53 Accuracy:0.65 \n",
      "ep 572: loss: 0.53 Accuracy:0.65 \n",
      "ep 573: loss: 0.53 Accuracy:0.65 \n",
      "ep 574: loss: 0.53 Accuracy:0.65 \n",
      "ep 575: loss: 0.53 Accuracy:0.65 \n",
      "ep 576: loss: 0.53 Accuracy:0.65 \n",
      "ep 577: loss: 0.53 Accuracy:0.65 \n",
      "ep 578: loss: 0.53 Accuracy:0.65 \n",
      "ep 579: loss: 0.53 Accuracy:0.65 \n",
      "ep 580: loss: 0.53 Accuracy:0.65 \n",
      "ep 581: loss: 0.53 Accuracy:0.65 \n",
      "ep 582: loss: 0.53 Accuracy:0.65 \n",
      "ep 583: loss: 0.53 Accuracy:0.65 \n",
      "ep 584: loss: 0.53 Accuracy:0.65 \n",
      "ep 585: loss: 0.53 Accuracy:0.65 \n",
      "ep 586: loss: 0.53 Accuracy:0.65 \n",
      "ep 587: loss: 0.53 Accuracy:0.65 \n",
      "ep 588: loss: 0.53 Accuracy:0.65 \n",
      "ep 589: loss: 0.53 Accuracy:0.65 \n",
      "ep 590: loss: 0.53 Accuracy:0.65 \n",
      "ep 591: loss: 0.53 Accuracy:0.65 \n",
      "ep 592: loss: 0.53 Accuracy:0.65 \n",
      "ep 593: loss: 0.53 Accuracy:0.65 \n",
      "ep 594: loss: 0.53 Accuracy:0.65 \n",
      "ep 595: loss: 0.53 Accuracy:0.65 \n",
      "ep 596: loss: 0.53 Accuracy:0.65 \n",
      "ep 597: loss: 0.53 Accuracy:0.65 \n",
      "ep 598: loss: 0.53 Accuracy:0.65 \n",
      "ep 599: loss: 0.53 Accuracy:0.65 \n",
      "ep 600: loss: 0.52 Accuracy:0.65 \n",
      "ep 601: loss: 0.52 Accuracy:0.65 \n",
      "ep 602: loss: 0.52 Accuracy:0.65 \n",
      "ep 603: loss: 0.52 Accuracy:0.65 \n",
      "ep 604: loss: 0.52 Accuracy:0.65 \n",
      "ep 605: loss: 0.52 Accuracy:0.65 \n",
      "ep 606: loss: 0.52 Accuracy:0.65 \n",
      "ep 607: loss: 0.52 Accuracy:0.65 \n",
      "ep 608: loss: 0.52 Accuracy:0.65 \n",
      "ep 609: loss: 0.52 Accuracy:0.65 \n",
      "ep 610: loss: 0.52 Accuracy:0.65 \n",
      "ep 611: loss: 0.52 Accuracy:0.65 \n",
      "ep 612: loss: 0.52 Accuracy:0.65 \n",
      "ep 613: loss: 0.52 Accuracy:0.65 \n",
      "ep 614: loss: 0.52 Accuracy:0.65 \n",
      "ep 615: loss: 0.52 Accuracy:0.65 \n",
      "ep 616: loss: 0.52 Accuracy:0.65 \n",
      "ep 617: loss: 0.52 Accuracy:0.65 \n",
      "ep 618: loss: 0.52 Accuracy:0.65 \n",
      "ep 619: loss: 0.52 Accuracy:0.65 \n",
      "ep 620: loss: 0.52 Accuracy:0.65 \n",
      "ep 621: loss: 0.52 Accuracy:0.65 \n",
      "ep 622: loss: 0.52 Accuracy:0.65 \n",
      "ep 623: loss: 0.52 Accuracy:0.65 \n",
      "ep 624: loss: 0.52 Accuracy:0.65 \n",
      "ep 625: loss: 0.52 Accuracy:0.65 \n",
      "ep 626: loss: 0.52 Accuracy:0.65 \n",
      "ep 627: loss: 0.52 Accuracy:0.65 \n",
      "ep 628: loss: 0.52 Accuracy:0.65 \n",
      "ep 629: loss: 0.52 Accuracy:0.65 \n",
      "ep 630: loss: 0.51 Accuracy:0.65 \n",
      "ep 631: loss: 0.51 Accuracy:0.65 \n",
      "ep 632: loss: 0.51 Accuracy:0.65 \n",
      "ep 633: loss: 0.51 Accuracy:0.65 \n",
      "ep 634: loss: 0.51 Accuracy:0.65 \n",
      "ep 635: loss: 0.51 Accuracy:0.65 \n",
      "ep 636: loss: 0.51 Accuracy:0.65 \n",
      "ep 637: loss: 0.51 Accuracy:0.65 \n",
      "ep 638: loss: 0.51 Accuracy:0.65 \n",
      "ep 639: loss: 0.51 Accuracy:0.65 \n",
      "ep 640: loss: 0.51 Accuracy:0.65 \n",
      "ep 641: loss: 0.51 Accuracy:0.65 \n",
      "ep 642: loss: 0.51 Accuracy:0.65 \n",
      "ep 643: loss: 0.51 Accuracy:0.65 \n",
      "ep 644: loss: 0.51 Accuracy:0.65 \n",
      "ep 645: loss: 0.51 Accuracy:0.65 \n",
      "ep 646: loss: 0.51 Accuracy:0.65 \n",
      "ep 647: loss: 0.51 Accuracy:0.65 \n",
      "ep 648: loss: 0.51 Accuracy:0.65 \n",
      "ep 649: loss: 0.51 Accuracy:0.65 \n",
      "ep 650: loss: 0.51 Accuracy:0.65 \n",
      "ep 651: loss: 0.51 Accuracy:0.65 \n",
      "ep 652: loss: 0.51 Accuracy:0.65 \n",
      "ep 653: loss: 0.51 Accuracy:0.65 \n",
      "ep 654: loss: 0.51 Accuracy:0.65 \n",
      "ep 655: loss: 0.51 Accuracy:0.65 \n",
      "ep 656: loss: 0.51 Accuracy:0.65 \n",
      "ep 657: loss: 0.51 Accuracy:0.65 \n",
      "ep 658: loss: 0.51 Accuracy:0.65 \n",
      "ep 659: loss: 0.51 Accuracy:0.65 \n",
      "ep 660: loss: 0.51 Accuracy:0.65 \n",
      "ep 661: loss: 0.51 Accuracy:0.65 \n",
      "ep 662: loss: 0.50 Accuracy:0.65 \n",
      "ep 663: loss: 0.50 Accuracy:0.65 \n",
      "ep 664: loss: 0.50 Accuracy:0.65 \n",
      "ep 665: loss: 0.50 Accuracy:0.65 \n",
      "ep 666: loss: 0.50 Accuracy:0.65 \n",
      "ep 667: loss: 0.50 Accuracy:0.65 \n",
      "ep 668: loss: 0.50 Accuracy:0.65 \n",
      "ep 669: loss: 0.50 Accuracy:0.65 \n",
      "ep 670: loss: 0.50 Accuracy:0.65 \n",
      "ep 671: loss: 0.50 Accuracy:0.65 \n",
      "ep 672: loss: 0.50 Accuracy:0.65 \n",
      "ep 673: loss: 0.50 Accuracy:0.65 \n",
      "ep 674: loss: 0.50 Accuracy:0.65 \n",
      "ep 675: loss: 0.50 Accuracy:0.65 \n",
      "ep 676: loss: 0.50 Accuracy:0.65 \n",
      "ep 677: loss: 0.50 Accuracy:0.65 \n",
      "ep 678: loss: 0.50 Accuracy:0.65 \n",
      "ep 679: loss: 0.50 Accuracy:0.65 \n",
      "ep 680: loss: 0.50 Accuracy:0.65 \n",
      "ep 681: loss: 0.50 Accuracy:0.65 \n",
      "ep 682: loss: 0.50 Accuracy:0.65 \n",
      "ep 683: loss: 0.50 Accuracy:0.65 \n",
      "ep 684: loss: 0.50 Accuracy:0.65 \n",
      "ep 685: loss: 0.50 Accuracy:0.65 \n",
      "ep 686: loss: 0.50 Accuracy:0.65 \n",
      "ep 687: loss: 0.50 Accuracy:0.65 \n",
      "ep 688: loss: 0.50 Accuracy:0.65 \n",
      "ep 689: loss: 0.50 Accuracy:0.65 \n",
      "ep 690: loss: 0.50 Accuracy:0.65 \n",
      "ep 691: loss: 0.50 Accuracy:0.65 \n",
      "ep 692: loss: 0.50 Accuracy:0.65 \n",
      "ep 693: loss: 0.50 Accuracy:0.65 \n",
      "ep 694: loss: 0.50 Accuracy:0.65 \n",
      "ep 695: loss: 0.50 Accuracy:0.65 \n",
      "ep 696: loss: 0.49 Accuracy:0.65 \n",
      "ep 697: loss: 0.49 Accuracy:0.65 \n",
      "ep 698: loss: 0.49 Accuracy:0.65 \n",
      "ep 699: loss: 0.49 Accuracy:0.65 \n",
      "ep 700: loss: 0.49 Accuracy:0.65 \n",
      "ep 701: loss: 0.49 Accuracy:0.65 \n",
      "ep 702: loss: 0.49 Accuracy:0.65 \n",
      "ep 703: loss: 0.49 Accuracy:0.65 \n",
      "ep 704: loss: 0.49 Accuracy:0.65 \n",
      "ep 705: loss: 0.49 Accuracy:0.65 \n",
      "ep 706: loss: 0.49 Accuracy:0.65 \n",
      "ep 707: loss: 0.49 Accuracy:0.65 \n",
      "ep 708: loss: 0.49 Accuracy:0.65 \n",
      "ep 709: loss: 0.49 Accuracy:0.65 \n",
      "ep 710: loss: 0.49 Accuracy:0.65 \n",
      "ep 711: loss: 0.49 Accuracy:0.65 \n",
      "ep 712: loss: 0.49 Accuracy:0.65 \n",
      "ep 713: loss: 0.49 Accuracy:0.65 \n",
      "ep 714: loss: 0.49 Accuracy:0.65 \n",
      "ep 715: loss: 0.49 Accuracy:0.65 \n",
      "ep 716: loss: 0.49 Accuracy:0.65 \n",
      "ep 717: loss: 0.49 Accuracy:0.65 \n",
      "ep 718: loss: 0.49 Accuracy:0.65 \n",
      "ep 719: loss: 0.49 Accuracy:0.65 \n",
      "ep 720: loss: 0.49 Accuracy:0.65 \n",
      "ep 721: loss: 0.49 Accuracy:0.65 \n",
      "ep 722: loss: 0.49 Accuracy:0.65 \n",
      "ep 723: loss: 0.49 Accuracy:0.65 \n",
      "ep 724: loss: 0.49 Accuracy:0.65 \n",
      "ep 725: loss: 0.49 Accuracy:0.65 \n",
      "ep 726: loss: 0.49 Accuracy:0.65 \n",
      "ep 727: loss: 0.49 Accuracy:0.65 \n",
      "ep 728: loss: 0.49 Accuracy:0.65 \n",
      "ep 729: loss: 0.49 Accuracy:0.65 \n",
      "ep 730: loss: 0.49 Accuracy:0.65 \n",
      "ep 731: loss: 0.48 Accuracy:0.65 \n",
      "ep 732: loss: 0.48 Accuracy:0.65 \n",
      "ep 733: loss: 0.48 Accuracy:0.65 \n",
      "ep 734: loss: 0.48 Accuracy:0.65 \n",
      "ep 735: loss: 0.48 Accuracy:0.65 \n",
      "ep 736: loss: 0.48 Accuracy:0.65 \n",
      "ep 737: loss: 0.48 Accuracy:0.65 \n",
      "ep 738: loss: 0.48 Accuracy:0.65 \n",
      "ep 739: loss: 0.48 Accuracy:0.65 \n",
      "ep 740: loss: 0.48 Accuracy:0.65 \n",
      "ep 741: loss: 0.48 Accuracy:0.65 \n",
      "ep 742: loss: 0.48 Accuracy:0.65 \n",
      "ep 743: loss: 0.48 Accuracy:0.65 \n",
      "ep 744: loss: 0.48 Accuracy:0.65 \n",
      "ep 745: loss: 0.48 Accuracy:0.65 \n",
      "ep 746: loss: 0.48 Accuracy:0.65 \n",
      "ep 747: loss: 0.48 Accuracy:0.65 \n",
      "ep 748: loss: 0.48 Accuracy:0.65 \n",
      "ep 749: loss: 0.48 Accuracy:0.65 \n",
      "ep 750: loss: 0.48 Accuracy:0.65 \n",
      "ep 751: loss: 0.48 Accuracy:0.65 \n",
      "ep 752: loss: 0.48 Accuracy:0.65 \n",
      "ep 753: loss: 0.48 Accuracy:0.65 \n",
      "ep 754: loss: 0.48 Accuracy:0.65 \n",
      "ep 755: loss: 0.48 Accuracy:0.65 \n",
      "ep 756: loss: 0.48 Accuracy:0.65 \n",
      "ep 757: loss: 0.48 Accuracy:0.65 \n",
      "ep 758: loss: 0.48 Accuracy:0.65 \n",
      "ep 759: loss: 0.48 Accuracy:0.65 \n",
      "ep 760: loss: 0.48 Accuracy:0.65 \n",
      "ep 761: loss: 0.48 Accuracy:0.65 \n",
      "ep 762: loss: 0.48 Accuracy:0.65 \n",
      "ep 763: loss: 0.48 Accuracy:0.65 \n",
      "ep 764: loss: 0.48 Accuracy:0.65 \n",
      "ep 765: loss: 0.48 Accuracy:0.65 \n",
      "ep 766: loss: 0.48 Accuracy:0.65 \n",
      "ep 767: loss: 0.48 Accuracy:0.65 \n",
      "ep 768: loss: 0.48 Accuracy:0.65 \n",
      "ep 769: loss: 0.48 Accuracy:0.65 \n",
      "ep 770: loss: 0.47 Accuracy:0.65 \n",
      "ep 771: loss: 0.47 Accuracy:0.65 \n",
      "ep 772: loss: 0.47 Accuracy:0.65 \n",
      "ep 773: loss: 0.47 Accuracy:0.65 \n",
      "ep 774: loss: 0.47 Accuracy:0.65 \n",
      "ep 775: loss: 0.47 Accuracy:0.65 \n",
      "ep 776: loss: 0.47 Accuracy:0.65 \n",
      "ep 777: loss: 0.47 Accuracy:0.65 \n",
      "ep 778: loss: 0.47 Accuracy:0.65 \n",
      "ep 779: loss: 0.47 Accuracy:0.65 \n",
      "ep 780: loss: 0.47 Accuracy:0.65 \n",
      "ep 781: loss: 0.47 Accuracy:0.65 \n",
      "ep 782: loss: 0.47 Accuracy:0.65 \n",
      "ep 783: loss: 0.47 Accuracy:0.65 \n",
      "ep 784: loss: 0.47 Accuracy:0.65 \n",
      "ep 785: loss: 0.47 Accuracy:0.65 \n",
      "ep 786: loss: 0.47 Accuracy:0.65 \n",
      "ep 787: loss: 0.47 Accuracy:0.65 \n",
      "ep 788: loss: 0.47 Accuracy:0.65 \n",
      "ep 789: loss: 0.47 Accuracy:0.65 \n",
      "ep 790: loss: 0.47 Accuracy:0.65 \n",
      "ep 791: loss: 0.47 Accuracy:0.65 \n",
      "ep 792: loss: 0.47 Accuracy:0.65 \n",
      "ep 793: loss: 0.47 Accuracy:0.65 \n",
      "ep 794: loss: 0.47 Accuracy:0.65 \n",
      "ep 795: loss: 0.47 Accuracy:0.65 \n",
      "ep 796: loss: 0.47 Accuracy:0.65 \n",
      "ep 797: loss: 0.47 Accuracy:0.65 \n",
      "ep 798: loss: 0.47 Accuracy:0.65 \n",
      "ep 799: loss: 0.47 Accuracy:0.65 \n",
      "ep 800: loss: 0.47 Accuracy:0.65 \n",
      "ep 801: loss: 0.47 Accuracy:0.65 \n",
      "ep 802: loss: 0.47 Accuracy:0.65 \n",
      "ep 803: loss: 0.47 Accuracy:0.65 \n",
      "ep 804: loss: 0.47 Accuracy:0.65 \n",
      "ep 805: loss: 0.47 Accuracy:0.65 \n",
      "ep 806: loss: 0.47 Accuracy:0.65 \n",
      "ep 807: loss: 0.47 Accuracy:0.65 \n",
      "ep 808: loss: 0.47 Accuracy:0.65 \n",
      "ep 809: loss: 0.47 Accuracy:0.65 \n",
      "ep 810: loss: 0.46 Accuracy:0.65 \n",
      "ep 811: loss: 0.46 Accuracy:0.65 \n",
      "ep 812: loss: 0.46 Accuracy:0.65 \n",
      "ep 813: loss: 0.46 Accuracy:0.65 \n",
      "ep 814: loss: 0.46 Accuracy:0.65 \n",
      "ep 815: loss: 0.46 Accuracy:0.65 \n",
      "ep 816: loss: 0.46 Accuracy:0.65 \n",
      "ep 817: loss: 0.46 Accuracy:0.65 \n",
      "ep 818: loss: 0.46 Accuracy:0.65 \n",
      "ep 819: loss: 0.46 Accuracy:0.65 \n",
      "ep 820: loss: 0.46 Accuracy:0.65 \n",
      "ep 821: loss: 0.46 Accuracy:0.65 \n",
      "ep 822: loss: 0.46 Accuracy:0.65 \n",
      "ep 823: loss: 0.46 Accuracy:0.65 \n",
      "ep 824: loss: 0.46 Accuracy:0.65 \n",
      "ep 825: loss: 0.46 Accuracy:0.65 \n",
      "ep 826: loss: 0.46 Accuracy:0.65 \n",
      "ep 827: loss: 0.46 Accuracy:0.65 \n",
      "ep 828: loss: 0.46 Accuracy:0.65 \n",
      "ep 829: loss: 0.46 Accuracy:0.65 \n",
      "ep 830: loss: 0.46 Accuracy:0.65 \n",
      "ep 831: loss: 0.46 Accuracy:0.65 \n",
      "ep 832: loss: 0.46 Accuracy:0.65 \n",
      "ep 833: loss: 0.46 Accuracy:0.65 \n",
      "ep 834: loss: 0.46 Accuracy:0.65 \n",
      "ep 835: loss: 0.46 Accuracy:0.65 \n",
      "ep 836: loss: 0.46 Accuracy:0.65 \n",
      "ep 837: loss: 0.46 Accuracy:0.65 \n",
      "ep 838: loss: 0.46 Accuracy:0.65 \n",
      "ep 839: loss: 0.46 Accuracy:0.65 \n",
      "ep 840: loss: 0.46 Accuracy:0.65 \n",
      "ep 841: loss: 0.46 Accuracy:0.65 \n",
      "ep 842: loss: 0.46 Accuracy:0.65 \n",
      "ep 843: loss: 0.46 Accuracy:0.65 \n",
      "ep 844: loss: 0.46 Accuracy:0.65 \n",
      "ep 845: loss: 0.46 Accuracy:0.65 \n",
      "ep 846: loss: 0.46 Accuracy:0.65 \n",
      "ep 847: loss: 0.46 Accuracy:0.65 \n",
      "ep 848: loss: 0.46 Accuracy:0.65 \n",
      "ep 849: loss: 0.46 Accuracy:0.65 \n",
      "ep 850: loss: 0.46 Accuracy:0.65 \n",
      "ep 851: loss: 0.46 Accuracy:0.65 \n",
      "ep 852: loss: 0.46 Accuracy:0.65 \n",
      "ep 853: loss: 0.46 Accuracy:0.65 \n",
      "ep 854: loss: 0.46 Accuracy:0.65 \n",
      "ep 855: loss: 0.45 Accuracy:0.65 \n",
      "ep 856: loss: 0.45 Accuracy:0.65 \n",
      "ep 857: loss: 0.45 Accuracy:0.65 \n",
      "ep 858: loss: 0.45 Accuracy:0.65 \n",
      "ep 859: loss: 0.45 Accuracy:0.65 \n",
      "ep 860: loss: 0.45 Accuracy:0.65 \n",
      "ep 861: loss: 0.45 Accuracy:0.65 \n",
      "ep 862: loss: 0.45 Accuracy:0.65 \n",
      "ep 863: loss: 0.45 Accuracy:0.65 \n",
      "ep 864: loss: 0.45 Accuracy:0.65 \n",
      "ep 865: loss: 0.45 Accuracy:0.65 \n",
      "ep 866: loss: 0.45 Accuracy:0.65 \n",
      "ep 867: loss: 0.45 Accuracy:0.65 \n",
      "ep 868: loss: 0.45 Accuracy:0.65 \n",
      "ep 869: loss: 0.45 Accuracy:0.65 \n",
      "ep 870: loss: 0.45 Accuracy:0.65 \n",
      "ep 871: loss: 0.45 Accuracy:0.65 \n",
      "ep 872: loss: 0.45 Accuracy:0.65 \n",
      "ep 873: loss: 0.45 Accuracy:0.65 \n",
      "ep 874: loss: 0.45 Accuracy:0.65 \n",
      "ep 875: loss: 0.45 Accuracy:0.65 \n",
      "ep 876: loss: 0.45 Accuracy:0.65 \n",
      "ep 877: loss: 0.45 Accuracy:0.65 \n",
      "ep 878: loss: 0.45 Accuracy:0.65 \n",
      "ep 879: loss: 0.45 Accuracy:0.65 \n",
      "ep 880: loss: 0.45 Accuracy:0.65 \n",
      "ep 881: loss: 0.45 Accuracy:0.65 \n",
      "ep 882: loss: 0.45 Accuracy:0.65 \n",
      "ep 883: loss: 0.45 Accuracy:0.65 \n",
      "ep 884: loss: 0.45 Accuracy:0.65 \n",
      "ep 885: loss: 0.45 Accuracy:0.65 \n",
      "ep 886: loss: 0.45 Accuracy:0.65 \n",
      "ep 887: loss: 0.45 Accuracy:0.65 \n",
      "ep 888: loss: 0.45 Accuracy:0.65 \n",
      "ep 889: loss: 0.45 Accuracy:0.65 \n",
      "ep 890: loss: 0.45 Accuracy:0.65 \n",
      "ep 891: loss: 0.45 Accuracy:0.65 \n",
      "ep 892: loss: 0.45 Accuracy:0.65 \n",
      "ep 893: loss: 0.45 Accuracy:0.65 \n",
      "ep 894: loss: 0.45 Accuracy:0.65 \n",
      "ep 895: loss: 0.45 Accuracy:0.65 \n",
      "ep 896: loss: 0.45 Accuracy:0.65 \n",
      "ep 897: loss: 0.45 Accuracy:0.65 \n",
      "ep 898: loss: 0.45 Accuracy:0.65 \n",
      "ep 899: loss: 0.45 Accuracy:0.65 \n",
      "ep 900: loss: 0.45 Accuracy:0.65 \n",
      "ep 901: loss: 0.45 Accuracy:0.65 \n",
      "ep 902: loss: 0.45 Accuracy:0.65 \n",
      "ep 903: loss: 0.44 Accuracy:0.65 \n",
      "ep 904: loss: 0.44 Accuracy:0.65 \n",
      "ep 905: loss: 0.44 Accuracy:0.65 \n",
      "ep 906: loss: 0.44 Accuracy:0.65 \n",
      "ep 907: loss: 0.44 Accuracy:0.65 \n",
      "ep 908: loss: 0.44 Accuracy:0.65 \n",
      "ep 909: loss: 0.44 Accuracy:0.65 \n",
      "ep 910: loss: 0.44 Accuracy:0.65 \n",
      "ep 911: loss: 0.44 Accuracy:0.65 \n",
      "ep 912: loss: 0.44 Accuracy:0.65 \n",
      "ep 913: loss: 0.44 Accuracy:0.65 \n",
      "ep 914: loss: 0.44 Accuracy:0.65 \n",
      "ep 915: loss: 0.44 Accuracy:0.65 \n",
      "ep 916: loss: 0.44 Accuracy:0.65 \n",
      "ep 917: loss: 0.44 Accuracy:0.65 \n",
      "ep 918: loss: 0.44 Accuracy:0.65 \n",
      "ep 919: loss: 0.44 Accuracy:0.65 \n",
      "ep 920: loss: 0.44 Accuracy:0.65 \n",
      "ep 921: loss: 0.44 Accuracy:0.65 \n",
      "ep 922: loss: 0.44 Accuracy:0.65 \n",
      "ep 923: loss: 0.44 Accuracy:0.65 \n",
      "ep 924: loss: 0.44 Accuracy:0.65 \n",
      "ep 925: loss: 0.44 Accuracy:0.65 \n",
      "ep 926: loss: 0.44 Accuracy:0.65 \n",
      "ep 927: loss: 0.44 Accuracy:0.65 \n",
      "ep 928: loss: 0.44 Accuracy:0.65 \n",
      "ep 929: loss: 0.44 Accuracy:0.65 \n",
      "ep 930: loss: 0.44 Accuracy:0.65 \n",
      "ep 931: loss: 0.44 Accuracy:0.65 \n",
      "ep 932: loss: 0.44 Accuracy:0.65 \n",
      "ep 933: loss: 0.44 Accuracy:0.65 \n",
      "ep 934: loss: 0.44 Accuracy:0.65 \n",
      "ep 935: loss: 0.44 Accuracy:0.65 \n",
      "ep 936: loss: 0.44 Accuracy:0.65 \n",
      "ep 937: loss: 0.44 Accuracy:0.65 \n",
      "ep 938: loss: 0.44 Accuracy:0.65 \n",
      "ep 939: loss: 0.44 Accuracy:0.65 \n",
      "ep 940: loss: 0.44 Accuracy:0.65 \n",
      "ep 941: loss: 0.44 Accuracy:0.65 \n",
      "ep 942: loss: 0.44 Accuracy:0.65 \n",
      "ep 943: loss: 0.44 Accuracy:0.65 \n",
      "ep 944: loss: 0.44 Accuracy:0.65 \n",
      "ep 945: loss: 0.44 Accuracy:0.65 \n",
      "ep 946: loss: 0.44 Accuracy:0.65 \n",
      "ep 947: loss: 0.44 Accuracy:0.65 \n",
      "ep 948: loss: 0.44 Accuracy:0.65 \n",
      "ep 949: loss: 0.44 Accuracy:0.65 \n",
      "ep 950: loss: 0.44 Accuracy:0.65 \n",
      "ep 951: loss: 0.44 Accuracy:0.65 \n",
      "ep 952: loss: 0.44 Accuracy:0.65 \n",
      "ep 953: loss: 0.44 Accuracy:0.65 \n",
      "ep 954: loss: 0.44 Accuracy:0.65 \n",
      "ep 955: loss: 0.43 Accuracy:0.65 \n",
      "ep 956: loss: 0.43 Accuracy:0.65 \n",
      "ep 957: loss: 0.43 Accuracy:0.65 \n",
      "ep 958: loss: 0.43 Accuracy:0.65 \n",
      "ep 959: loss: 0.43 Accuracy:0.65 \n",
      "ep 960: loss: 0.43 Accuracy:0.65 \n",
      "ep 961: loss: 0.43 Accuracy:0.65 \n",
      "ep 962: loss: 0.43 Accuracy:0.65 \n",
      "ep 963: loss: 0.43 Accuracy:0.65 \n",
      "ep 964: loss: 0.43 Accuracy:0.65 \n",
      "ep 965: loss: 0.43 Accuracy:0.65 \n",
      "ep 966: loss: 0.43 Accuracy:0.65 \n",
      "ep 967: loss: 0.43 Accuracy:0.65 \n",
      "ep 968: loss: 0.43 Accuracy:0.65 \n",
      "ep 969: loss: 0.43 Accuracy:0.65 \n",
      "ep 970: loss: 0.43 Accuracy:0.65 \n",
      "ep 971: loss: 0.43 Accuracy:0.65 \n",
      "ep 972: loss: 0.43 Accuracy:0.65 \n",
      "ep 973: loss: 0.43 Accuracy:0.65 \n",
      "ep 974: loss: 0.43 Accuracy:0.66 \n",
      "ep 975: loss: 0.43 Accuracy:0.94 \n",
      "ep 976: loss: 0.43 Accuracy:0.95 \n",
      "ep 977: loss: 0.43 Accuracy:0.95 \n",
      "ep 978: loss: 0.43 Accuracy:0.95 \n",
      "ep 979: loss: 0.43 Accuracy:0.95 \n",
      "ep 980: loss: 0.43 Accuracy:0.95 \n",
      "ep 981: loss: 0.43 Accuracy:0.95 \n",
      "ep 982: loss: 0.43 Accuracy:0.95 \n",
      "ep 983: loss: 0.43 Accuracy:0.95 \n",
      "ep 984: loss: 0.43 Accuracy:0.95 \n",
      "ep 985: loss: 0.43 Accuracy:0.95 \n",
      "ep 986: loss: 0.43 Accuracy:0.95 \n",
      "ep 987: loss: 0.43 Accuracy:0.95 \n",
      "ep 988: loss: 0.43 Accuracy:0.95 \n",
      "ep 989: loss: 0.43 Accuracy:0.95 \n",
      "ep 990: loss: 0.43 Accuracy:0.95 \n",
      "ep 991: loss: 0.43 Accuracy:0.95 \n",
      "ep 992: loss: 0.43 Accuracy:0.95 \n",
      "ep 993: loss: 0.43 Accuracy:0.95 \n",
      "ep 994: loss: 0.43 Accuracy:0.95 \n",
      "ep 995: loss: 0.43 Accuracy:0.95 \n",
      "ep 996: loss: 0.43 Accuracy:0.95 \n",
      "ep 997: loss: 0.43 Accuracy:0.95 \n",
      "ep 998: loss: 0.43 Accuracy:0.95 \n",
      "ep 999: loss: 0.43 Accuracy:0.95 \n"
     ]
    }
   ],
   "source": [
    "epoches = 1000;\n",
    "rate = 3e-6;\n",
    "res_w = [];res_b = [];res_delta = [];res_dw = [];res_db = [];\n",
    "for p in range(epoches):\n",
    "    x0 = train_data;\n",
    "    # 正向传播\n",
    "    # 输入层情况\n",
    "    x[0] = np.dot(x0,w[0]) + b[0];\n",
    "    y[0] = func(act_fun[0],x[0]);\n",
    "    # 隐藏层\n",
    "    for k in range(1,layers):\n",
    "        x[k] = np.dot(y[k-1],w[k]) + b[k];\n",
    "        y[k] = func(act_fun[k],x[k]);\n",
    "    loss = func(loss_func,y[k],train_label);\n",
    "    if not type(metrics) == type(None):\n",
    "        y_pre = arg_max(y[k]);\n",
    "        evalue = evaluate(y_pre,train_label,metrics=metrics);\n",
    "    # 反向传播\n",
    "    # res_w.append([]);res_b.append([]);res_dw.append([]);res_db.append([]);res_delta.append([]);\n",
    "    # 输出层情况\n",
    "    delta[k] = gra_func(loss_func,y[k],train_label)*gra_func(act_fun[k],x[k]);\n",
    "    # delta量的归一化处理\n",
    "    # delta[k] = delta[k] / np.max(np.abs(delta[k]));\n",
    "    db = np.sum(delta[k],axis=0).reshape(1,-1);\n",
    "    dw = np.dot(y[k-1].T,delta[k]);\n",
    "    # res_w[p].append(copy.deepcopy(w[k]));res_b[p].append(copy.deepcopy(b[k]));res_delta[p].append(copy.deepcopy(delta[k]));res_dw[p].append(copy.deepcopy(dw));res_db[p].append(copy.deepcopy(db));\n",
    "    b[k] -= rate*db;\n",
    "    w[k] -= rate*dw;\n",
    "    k -= 1;\n",
    "    # 隐藏层\n",
    "    while(k>0):\n",
    "        delta[k] = np.dot(delta[k+1],w[k+1].T) * gra_func(act_fun[k],x[k]);\n",
    "        # delta的归一化处理\n",
    "        # delta[k] = delta[k] / np.max(np.abs(delta[k]));\n",
    "        db = np.sum(delta[k],axis = 0).reshape(1,-1);\n",
    "        dw = np.dot(y[k-1].T,delta[k]);\n",
    "        # res_w[p].append(copy.deepcopy(w[k]));\n",
    "        # res_b[p].append(copy.deepcopy(b[k]));\n",
    "        # res_delta[p].append(copy.deepcopy(delta[k]));\n",
    "        # res_dw[p].append(copy.deepcopy(dw));\n",
    "        # res_db[p].append(copy.deepcopy(db));\n",
    "        b[k] -= rate*db;\n",
    "        w[k] -= rate*dw;\n",
    "        k -= 1;\n",
    "    print('ep {}: loss: {:.2f}'.format(p,loss),end='');\n",
    "    if not type(metrics) == type(None):\n",
    "        print(' {}:{:.2f} '.format(metrics,evalue));\n",
    "    else:\n",
    "        print('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res_dw;\n",
    "abs_max = [];\n",
    "mean_data = [];\n",
    "med_data = [];\n",
    "abs_min = [];\n",
    "for i in range(len(data)):\n",
    "    abs_max.append([]);\n",
    "    mean_data.append([]);\n",
    "    med_data.append([]);\n",
    "    abs_min.append([]);\n",
    "\n",
    "    for k in range(len(data[i])-1,-1,-1):\n",
    "        abs_max[i].append(np.max(np.abs(data[i][k])));\n",
    "        mean_data[i].append(np.mean(data[i][k]));\n",
    "        med_data[i].append(np.median(data[i][k]));\n",
    "        abs_min[i].append(np.min(np.abs(data[i][k])));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.DataFrame(abs_max);\n",
    "writer = pd.ExcelWriter('abs_max.xlsx');\n",
    "data_pd.to_excel(writer,'page_1',float_format='%.6f');\n",
    "writer.save();\n",
    "writer.close();\n",
    "\n",
    "data_pd = pd.DataFrame(mean_data);\n",
    "writer = pd.ExcelWriter('mean_data.xlsx');\n",
    "data_pd.to_excel(writer,'page_1',float_format='%.6f');\n",
    "writer.save();\n",
    "writer.close();\n",
    "\n",
    "data_pd = pd.DataFrame(med_data);\n",
    "writer = pd.ExcelWriter('med_data.xlsx');\n",
    "data_pd.to_excel(writer,'page_1',float_format='%.6f');\n",
    "writer.save();\n",
    "writer.close();\n",
    "\n",
    "data_pd = pd.DataFrame(abs_min);\n",
    "writer = pd.ExcelWriter('abs_min.xlsx');\n",
    "data_pd.to_excel(writer,'page_1',float_format='%.6f');\n",
    "writer.save();\n",
    "writer.close();"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce6f82c3eafde872384b2df90d4ff3d60be8762ce3510564dd0f34869981a8dc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
